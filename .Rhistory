rgnorm(1,
mu = 0,
alpha = level_GED_alpha,
beta = level_GED_beta) #What's the variance of this sum?
level_shock_mean <- mu_eps_star + p * M21_M22_mu_omega_star
level_shock_var <- ((level_GED_alpha)**2) * gamma(3/level_GED_beta) / (gamma(1/level_GED_beta)) + # https://search.r-project.org/CRAN/refmans/gnorm/html/gnorm.html
p * ((sigma_x**2) * (sigma_eps_star**2))
}
else if (level_model == 'M22') {
level_shock_vec[i] <- mu_eps_star +
as.numeric(as.matrix(VAR_process[shock_time_vec[i],])) %*% rnorm(p,M22_mu_eps_star,sigma_eps_star) +
rgnorm(1,
mu = 0,
alpha = level_GED_alpha,
beta = level_GED_beta) #What's the variance of this sum?
level_shock_mean <- mu_eps_star
level_shock_var <- ((level_GED_alpha)**2) * gamma(3/level_GED_beta) / (gamma(1/level_GED_beta)) + # https://search.r-project.org/CRAN/refmans/gnorm/html/gnorm.html
(sigma_x**2) * (sigma_eps_star**2)
}
else {level_shock_vec[i] <- rnorm(1, 0, sigma_GARCH_innov);
level_shock_mean <- 0;
level_shock_var <- sigma_GARCH_innov**2}
#Vol model
if (vol_model == 'M1'){
#Create volatility shock w*
vol_shock_vec[i] <- rnorm(1, mu_omega_star, vol_shock_sd)
vol_shock_mean <- mu_omega_star
vol_shock_var <- vol_shock_sd**2
vol_shock_kurtosis <- 0
shock_indicator <- c(
rep(0, shock_time_vec[i]),
rep(vol_shock_vec[i], vol_shock_length[i]),
rep(0, Tee[i] - shock_time_vec[i] - vol_shock_length[i]))
#Now add the design matrix to the list X
X[[i]] <- VAR_process
#Create GARCH model with shock(s)
GARCH_innov_vec <- c(
rnorm(shock_time_vec[i], 0, sigma_GARCH_innov),
level_shock_vec[i],
rnorm(Tee[i] - shock_time_vec[i] - 1, 0, sigma_GARCH_innov))
Y[[i]] <- garchxSim(Tee[i], arch = arch_param, garch = garch_param,
asym = asymmetry_param,
xreg =  as.matrix(shock_indicator),
innovations = GARCH_innov_vec, verbose = TRUE)
}
else if (vol_model == 'M21') {
vol_shock_vec[i] <- rnorm(1, mu_omega_star, vol_shock_sd) +
as.numeric(as.matrix(VAR_process[shock_time_vec[i],])) %*% M21_vol_cross_donor_random_effect
#What's the variance of this sum?
vol_shock_mean <- mu_omega_star
vol_shock_var <- vol_shock_sd**2 + p * ( (M21_M22_shock_sd**2) ) #variance of linear combination of
#random variables, where a_i are fixed
vol_shock_kurtosis <- 0
shock_indicator <- c(
rep(0, shock_time_vec[i]),
rep(vol_shock_vec[i], vol_shock_length[i]),
rep(0, Tee[i] - shock_time_vec[i] - vol_shock_length[i]))
#Now add the design matrix to the list X
X[[i]] <- VAR_process
#Create GARCH model with shock(s)
GARCH_innov_vec <- c(
rnorm(shock_time_vec[i], 0, sigma_GARCH_innov),
level_shock_vec[i],
rnorm(Tee[i] - shock_time_vec[i] - 1, 0, sigma_GARCH_innov))
Y[[i]] <- garchxSim(Tee[i], arch = arch_param, garch = garch_param,
asym = asymmetry_param,
xreg =  as.matrix(shock_indicator),
innovations = GARCH_innov_vec, verbose = TRUE)
}
else if (vol_model == 'M22') {
delta <- rnorm(p, M21_M22_mu_omega_star, M21_M22_shock_sd)
vol_shock_vec[i] <- rnorm(1, mu_omega_star, vol_shock_sd) +
as.numeric(as.matrix(VAR_process[shock_time_vec[i],])) %*% delta
#What's the variance of this sum?
vol_shock_mean <- mu_omega_star + p * M21_M22_mu_omega_star
vol_shock_var <- vol_shock_sd**2 + p * ( (sigma_x**2) * (M21_M22_shock_sd**2) )
vol_shock_kurtosis <- 0
shock_indicator <- c(
rep(0, shock_time_vec[i]),
rep(vol_shock_vec[i], vol_shock_length[i]),
rep(0, Tee[i] - shock_time_vec[i] - vol_shock_length[i]))
#Now add the design matrix to the list X
X[[i]] <- VAR_process
#Create GARCH model with shock(s)
GARCH_innov_vec <- c(
rnorm(shock_time_vec[i], 0, sigma_GARCH_innov),
level_shock_vec[i],
rnorm(Tee[i] - shock_time_vec[i] - 1, 0, sigma_GARCH_innov))
Y[[i]] <- garchxSim(Tee[i], arch = arch_param, garch = garch_param,
asym = asymmetry_param,
xreg =  as.matrix(shock_indicator),
innovations = GARCH_innov_vec, verbose = TRUE)
}
else {
#Create volatility shock w*
vol_shock_vec[i] <- rnorm(1, 0, sigma_GARCH_innov)
vol_shock_mean <- NA
vol_shock_var <- NA
vol_shock_kurtosis <- NA
#Now add the design matrix to the list X
X[[i]] <- VAR_process
#Create GARCH model with shock(s)
GARCH_innov_vec <- rnorm(Tee[i], 0, sigma_GARCH_innov)
Y[[i]] <- garchxSim(Tee[i], arch = arch_param, garch = garch_param,
asym = asymmetry_param,
innovations = GARCH_innov_vec, verbose = TRUE)
} #end conditionals that create vol shocks
T_star_plus_1_return_vec[i] <- Y[[i]][,1][shock_time_vec[i]+1,]
#Now we calculate the p-value for the volatility spike of length k
arch_param_count <- sum(ifelse(arch_param > 0, 1, 0))
garch_param_count <- sum(ifelse(garch_param > 0, 1, 0))
asymm_param_count <- sum(ifelse(asymmetry_param > 0, 1, 0))
indicator_vec <- as.matrix(c(rep(0,shock_time_vec[i]), rep(1,vol_shock_length[i])))
garch_1_1 <- garchx(Y[[i]][1:(shock_time_vec[i]+vol_shock_length[i]),1],
order = c(garch_param_count,arch_param_count,asymm_param_count),
xreg = indicator_vec[1:(shock_time_vec[i]+vol_shock_length[i])],
control = list(eval.max = 95000, iter.max = 95000 ),
hessian.control = list(maxit = 1000000))
xreg_est <- round(coeftest(garch_1_1)[ dim(coeftest(garch_1_1))[1], 1],5)
xreg_p_value <- round(coeftest(garch_1_1)[ dim(coeftest(garch_1_1))[1], dim(coeftest(garch_1_1))[2]],5)
xreg <- c(xreg, c(xreg_est, xreg_p_value))
} #end loop for n+1 series
#Now make xreg into a dataframe
xreg <- data.frame(matrix(xreg, nrow = n+1, byrow = TRUE))
## Compute summary statistics for output
level_shock_kurtosis <- gamma(5/level_GED_beta)*gamma(1/level_GED_beta)/( (gamma(3/level_GED_beta))**2 ) - 3 #https://en.wikipedia.org/wiki/Generalized_normal_distribution
T_star_sigma <- Y[[1]][,3][shock_time_vec[1],]
T_star_plus_1_sigma <- Y[[1]][,3][shock_time_vec[1]+1,]
T_star_plus_2_sigma <- Y[[1]][,3][shock_time_vec[1]+2,]
T_star_plus_3_sigma <- Y[[1]][,3][shock_time_vec[1]+3,]
##Output
cat('Simulation Summary Data','\n',
'-------------------------------------------------------------\n',
'Donors:', n, '\n',
'Series lengths:', Tee, '\n',
'Shock times:', shock_time_vec, '\n',
'Level Shock at T*+1:', round(level_shock_vec,2), '\n',
'T*+1: Return:', round(T_star_plus_1_return_vec,3), '\n',
'Volatility Shock at T*+1', round(vol_shock_vec,2), '\n',
'\n',
'Volatility of Time Series under Study', '\n',
'-------------------------------------------------------------\n',
'Sigma^2 at T*:', round(T_star_sigma,2), '\n',
'Sigma^2 at T*+1:', round(T_star_plus_1_sigma,2), '\n',
'Sigma^2 at T*+2:', round(T_star_plus_2_sigma,2), '\n',
'Sigma^2 at T*+3:', round(T_star_plus_3_sigma,2), '\n',
'\n',
'Level Shock Moments', '\n',
'-------------------------------------------------------------\n',
'Level Shock mean:', round(level_shock_mean,4), '(equivalent to a', round(level_shock_mean,2), '% daily move).', ' \n',
'Level Shock variance:', round(level_shock_var,4), '\n',
'Level Signal to Noise:', abs(round(level_shock_mean / sqrt(level_shock_var),2)) , '\n',
'Level Shock excess kurtosis:', round(level_shock_kurtosis, 2) , '\n',
'\n',
'Vol Shock Moments', '\n',
'-------------------------------------------------------------\n',
'Vol Shock mean:', round(vol_shock_mean,2), ' \n',
'Vol Shock variance:', round(vol_shock_var,4), '\n',
'Vol Signal to Noise:', abs(round(vol_shock_mean / sqrt(vol_shock_var),3)) , '\n',
'Vol Shock excess kurtosis:', round(vol_shock_kurtosis, 2)
)
#Plot the donors
par(mfrow = c(ceiling(sqrt(2*n + 2)), ceiling(sqrt(2*n + 2))))
for (i in 1:(n+1))
{
plot.ts(X[[i]][-c(1:20),], main = paste('Covariates of Donor ', i, sep = ''))
}
#Plot the time series
par(mfrow = c(ceiling(sqrt(n+1)), ceiling(sqrt(n+1))))
for (i in 1:(n+1))
{
plot.ts(Y[[i]][,1], ylim = c(min(Y[[i]][,1])*1.2, max(Y[[i]][,1])*1.2),
main = paste('y', i, ", GARCH(",length(arch_param),",",length(garch_param),") length = ",vol_shock_length[i],
"\n level shock = ",
round(level_shock_vec[i],2),
", vol shock = ",
round(vol_shock_vec[i],2),
'\n shock est = ', round(xreg[i,1],3), ', pval = ',round(xreg[i,2],3),
sep = ''), ylab = '100 * Daily Log-Return')
abline(v = shock_time_vec[i] + 1, col = 'red')
abline(h = 0, col = 'green')
}
#Plot the volatility series
par(mfrow = c(ceiling(sqrt(n+1)), ceiling(sqrt(n+1))))
for (i in 1:(n+1))
{
plot.ts(Y[[i]][-c(1:20),3], xlim=c(21, Tee[i]), main = paste('Volatility Series y', i,
", GARCH(",length(arch_param),",",length(garch_param),"), length = ",vol_shock_length[i],
"\n level shock = ",
round(level_shock_vec[i],2),
", vol shock = ",
round(vol_shock_vec[i],2),
'\n shock est = ', round(xreg[i,1],3), ', pval = ',round(xreg[i,2],3),
sep = ''), ylab = '')
abline(v = shock_time_vec[i] + 1, col = 'red')
title(ylab = expression(sigma^2), line = 2.05, cex.lab = 1.99)
}
#Items to return in a list
return(list(X, Y, Tee,shock_time_vec, xreg))
} #end of synth_vol_sim
# Here is the length of the vol shock we will use
inputted_n <- 8
inputted_vol_shock_length <- rdunif(inputted_n+1, 4, 7)
inputted_vol_shock_length <- rep(1, inputted_n+1)
output <- synth_vol_sim(n = inputted_n,
p = 9,
#model = c(1,1,1),
arch_param = c(.3),
garch_param = c(.5),
asymmetry_param = c(.15),
level_model = c('M1','M21','M22','none')[4],
vol_model = c('M1','M21','M22','none')[3],
sigma_GARCH_innov = 1, # this is the sd that goes into rnorm
sigma_x = 1,
min_shock_time = 5,
shock_time_vec = NULL,
level_shock_length = 1,
vol_shock_length = inputted_vol_shock_length,
a = 252,
b = 3 * 252,
mu_eps_star = -4.25,
M22_mu_eps_star = .8,
sigma_eps_star = .5,
mu_omega_star = .06,
vol_shock_sd = .03,
M21_M22_mu_omega_star = .02,
M21_M22_shock_sd = .01,
level_GED_alpha = .05 * sqrt(2),
level_GED_beta = 1.8)
rep(0, 10)
output <- synth_vol_sim(n = inputted_n,
p = 9,
#model = c(1,1,1),
arch_param = c(.3),
garch_param = c(.5),
asymmetry_param = c(.15),
level_model = c('M1','M21','M22','none')[4],
vol_model = c('M1','M21','M22','none')[3],
sigma_GARCH_innov = 1, # this is the sd that goes into rnorm
sigma_x = 1,
min_shock_time = 5,
shock_time_vec = NULL,
level_shock_length = 1,
vol_shock_length = inputted_vol_shock_length,
a = 252,
b = 3 * 252,
mu_eps_star = -4.25,
M22_mu_eps_star = .8,
sigma_eps_star = .5,
mu_omega_star = .06,
vol_shock_sd = .03,
M21_M22_mu_omega_star = .02,
M21_M22_shock_sd = .01,
level_GED_alpha = .05 * sqrt(2),
level_GED_beta = 1.8)
warnings()
#First, an distance-based weighting method function written by Jilei Lin (PhD Student at GWU)
# this function returns the W^* estimated by synthetic control method (SCM)
dbw <- function(X,
Tstar,
scale = FALSE,
sum_to_1 = 1,
bounded_below_by = 0,
bounded_above_by = 1) { # https://github.com/DEck13/synthetic_prediction/blob/master/prevalence_testing/numerical_studies/COP.R
# X is a list of covariates for the time series
# X[[1]] should be the covariate of the time series to predict
# X[[p]] for p = 2,...,n+1 are covariates for donors
# T^* is a vector of shock-effects time points
# shock effect point must be > 2
# number of time series for pool
n <- length(X) - 1
# covariate for time series for prediction
X1 <- X[[1]][Tstar[1], , drop = FALSE] # we get only 1 row
# covariates for time series pool
X0 <- c()
for (i in 1:n) {
X0[[i]] <- X[[i + 1]][Tstar[i + 1] + 1, , drop = FALSE] #get 1 row from each donor
}
if (scale == TRUE) { #begin if statement
dat <- rbind(X1, do.call('rbind', X0)) # do.call is for cluster computing?
dat <- apply(dat, 2, function(x) scale(x, center = TRUE, scale = TRUE))
X1 <- dat[1, , drop = FALSE]
X0 <- c()
for (i in 1:n) {
X0[[i]] <- dat[i + 1, , drop = FALSE] #we are repopulating X0[[i]] with scaled+centered data
} #end loop
} #end if statement
# objective function
weightedX0 <- function(W) {
# W is a vector of weight of the same length of X0
n <- length(W)
p <- ncol(X1)
XW <- matrix(0, nrow = 1, ncol = p)
for (i in 1:n) {
XW <- XW + W[i] * X0[[i]]
} #end of loop
norm <- as.numeric(crossprod(matrix(X1 - XW)))
return(norm)
} #end objective function
# optimization and return statement
# I have added features
# 1) The option to remove the sum-to-1 constraint
# 2) The option to change the lower bound to -1 or NA
# 3) option to change the upper bound to NA
#Thus I need if statements to implement these...
# conditional for sum to 1
if (is.na(sum_to_1) == FALSE) {eq_constraint <- function(W) sum(W) - 1 }
else{eq_constraint = NULL}
# conditional for bounding below
if (is.na(bounded_below_by) == FALSE)
{
lower_bound = rep(bounded_below_by, n)
}
else if (is.na(bounded_below_by) == TRUE)  {
lower_bound = NULL
}
#conditional for bounding above
if (is.na(bounded_above_by) == FALSE)
{
upper_bound = rep(1, n)
}
else if (is.na(bounded_above_by) == TRUE)  {
upper_bound = NULL
}
object_to_return <- solnp(par = rep(1/n, n),
fun = weightedX0,
eqfun = eq_constraint,
eqB = 0,
LB = lower_bound, UB = upper_bound,
control = list(trace = 0
, 1.0e-8
, tol = 1e-9
, outer.iter = 10000
, inner.iter = 10000))
return(object_to_return$pars)
} #end dbw function
#############################################################################
synth_vol_fit <- function(X,
Y,
T_star,
shock_est_vec,
shock_lengths)
{ #begin synth_vol_fit
## Doc String
# synth_vol_fit: function that takes (n+1)*(p+1) time series AND a vector of
# shock times as input and outputs
# 1) calculates a single weight vector w,
# 2) calculates a single fixed effects estimate vector omega*,
# 3) calculates the adjustment estimator vector \hat omega* for time series of interest
# 4) calculates the volatility of time series of interest at T*+1,T*+2,...,T*+k (i.e. the prediction)
# 5) calculates estimate of volatility on T*+1 for each series using each of three families, and
# 6) calculates the squared-error loss of the prediction
# Estimation/control options
# --Allow user to enter series of unequal lengths
# --Allow user to enter a vector of integers corresponding to the number of days
# the shock effect lasts for each outcome series
# --Allow user to pick a uniform model for each series (e.g. GARCH(1,1)) OR a BIC-minimizing
# model for each series (or mix and match).
# --Allow user to pick error distribution - see ugarchspec
##Input
# Y, a list of length n+1, with each entry containing a time series
# X, a list of length n+1, with each entry containing a dataframe of dimension y_i x p
# shock_time_vec, a vector of length n+1 containing shock time of each series
# shock_time_lengths, a vector of length n+1 containing shock time length of each series
#First, we get the vectors w for all sensible methods
w <- list() #initialize
matrix_of_specs <- matrix(c(rep(1,6),
rep(NA,6),
rep(c(0,-1,NA),4),
rep(c(1,NA), 6)),
byrow = FALSE, nrow = 12)
#We drop the 4th row because it's functionally no different from the first OR have lower bound > upper bound
matrix_of_specs <- matrix_of_specs[-4,]
for (i in 1:nrow(matrix_of_specs)){
w[[i]] <- dbw(X,
T_star,
scale = TRUE,
sum_to_1 = matrix_of_specs[i,1],
bounded_below_by = matrix_of_specs[i,2],
bounded_above_by = matrix_of_specs[i,3])
}
# Now we place these linear combinations into a matrix
w_mat <- matrix(unlist(w), nrow = nrow(matrix_of_specs), byrow = TRUE)
#Second, we calculate omega_star_hat, which is the dot product of w and the estimated shock effects
omega_star_hat_vec <- as.numeric(w_mat %*% shock_est_vec[-1])
#Third, we get a prediction to T*_+k
y_up_through_T_star <- Y[[1]][,1][1:T_star[1],1]
sigma2_up_through_T_star <- Y[[1]][,3][1:T_star[1],1]
y_up_through_T_star_plus_k <- Y[[1]][,1][1:(T_star[1] + shock_lengths[1]),1]
sigma2_up_through_T_star_plus_k <- Y[[1]][,3][1:(T_star[1] + shock_lengths[1]),1]
shock_period_only <- Y[[1]][,3][(T_star[1] + 1):(T_star[1] + shock_lengths[1]),1]
garch_1_1 <- garchx(y_up_through_T_star,
order = c(1,1,1),
control = list(eval.max = 1000000, iter.max = 1000000),
hessian.control = list(maxit = 1000000) )
pred <- as.numeric(predict(garch_1_1, n.ahead = shock_lengths[1]))
adjusted_pred_list <- list() # the ith entry will be using the ith linear combination
MSE_adjusted <- list()
for (i in 1:length(omega_star_hat_vec))
{
adjusted_pred <- pred + omega_star_hat_vec[i]
adjusted_pred_list[[i]] <- pmax(adjusted_pred, 0)
MSE_adjusted[[i]] <- sum((shock_period_only - adjusted_pred)**2)
}
#Last, we calculate MSE for unadjusted
MSE_unadjusted <- sum((shock_period_only - pred)**2)
#Who won?
alternative_wins <- MSE_adjusted < MSE_unadjusted
#We now make a vector with the names of each of the sensible linear combinations
linear_comb_names <- c('Convex Hull',
'1 -1 NA',
'Drop Bounded Below',
'Unit Ball: Sum-to-1 (L1 Norm Vec)',
'Affine Hull',
'Drop Sum-to-1',
'Bounded Below by -1',
'Bounded Above by 1',
'Conic Hull',
'Unit Ball',
'Unrestricted')
#Plot the donor pool weights
par(mfrow=c(ceiling(sqrt(length(linear_comb_names))),ceiling(sqrt(length(linear_comb_names)))))
for (i in 1:nrow(w_mat))
{
minn <- min(w_mat[i,])
maxx <- max(w_mat[i,])
if (minn == maxx)
{
minn <- -1 * abs(minn)
maxx  <- -1 * abs(max)
}
barplot(w_mat[i,],
main = paste('Donor Pool Weights:\n',
linear_comb_names[i]),
names.arg = 2:(length(T_star)),
ylim = c(minn,
maxx))
}
#Now let's plot the adjustment
par(mfrow=c(1,2))
trimmed_prediction_vec_for_plotting <- Winsorize(unlist(adjusted_pred_list), probs = c(0, 0.72))
#PLOT ON THE LEFT:
plot(sigma2_up_through_T_star_plus_k,
main = 'GARCH Prediction versus \nAdjusted Predictions versus Actual',
ylab = '',
xlab = "Time",
xlim = c(0, length(sigma2_up_through_T_star_plus_k) + 5),
ylim = c(0,  max(pred, trimmed_prediction_vec_for_plotting, sigma2_up_through_T_star_plus_k) ) )
title(ylab = expression(sigma^2), line = 2.05, cex.lab = 1.99)            # Add y-axis text
# We also plot, in a different line style, the post-shock period
lines(y = c(sigma2_up_through_T_star[T_star[1]],  shock_period_only),
x = T_star[1]:(T_star[1]+shock_lengths[1]),  lty=2, lwd=2,
ylim = c(0,  max(pred, trimmed_prediction_vec_for_plotting, sigma2_up_through_T_star_plus_k) ) )
# Here is the color scheme we will use
colors_for_adjusted_pred <- c('black', 'red',
brewer.pal(length(omega_star_hat_vec),'Set3'))
# Let's add the ground truth
points(y = shock_period_only,
x = (T_star[1]+1):(T_star[1]+shock_lengths[1]),
col = colors_for_adjusted_pred[1],
cex = 1.3, pch = 16)
# Let's add the plain old GARCH prediction
points(y = pred,
x = (T_star[1]+1):(T_star[1]+shock_lengths[1]),
col = colors_for_adjusted_pred[2],
cex = 1.3, pch = 15)
# Now plot the adjusted predictions
for (i in 1:(length(omega_star_hat_vec)))
{
points(y = adjusted_pred_list[[i]], x = (T_star[1]+1):(T_star[1]+shock_lengths[1]),
col = colors_for_adjusted_pred[i+2], cex = 1.9, pch = 10)
}
labels_for_legend <- c('Actual','GARCH (unadjusted)',linear_comb_names)
legend(x = "topleft",  # Coordinates (x also accepts keywords)
legend = labels_for_legend,
1:length(labels_for_legend), # Vector with the name of each group
colors_for_adjusted_pred,   # Creates boxes in the legend with the specified colors
title = 'Prediction Method',      # Legend title,
cex = .9
)
#PLOT ON THE RIGHT
plot.ts(fitted(garch_1_1),
main = 'Pre-shock GARCH fitted values (green) \nversus Actual (black)',
ylab = '', col = 'green',
ylim = c(0, max(fitted(garch_1_1), sigma2_up_through_T_star)) ,
cex.lab = 3.99)
lines(sigma2_up_through_T_star, col = 'black')
title(ylab = expression(sigma^2), line = 2.05, cex.lab = 1.99)
return(list(w = round(w_mat,3),
omega_star_hat = round(omega_star_hat_vec, 3),
adjusted_pred = adjusted_pred_list,
garch_pred = round(pred,3),
ground_truth = round(shock_period_only,3),
MSE_adjusted = MSE_adjusted,
MSE_unadjusted = round(MSE_unadjusted,3),
alternative_wins = alternative_wins))
} #end of synth_vol_fit
# Let's now use the function
X_demo <- output[[1]]
Y_demo <- output[[2]]
T_star_demo <- output[[4]]
shock_effect_vec_demo <- output[[5]][,1]
synth_vol_fit(X_demo,
Y_demo,
T_star_demo,
shock_effect_vec_demo,
inputted_vol_shock_length)
fitting_output<- synth_vol_fit(X_demo,
Y_demo,
T_star_demo,
shock_effect_vec_demo,
inputted_vol_shock_length)
