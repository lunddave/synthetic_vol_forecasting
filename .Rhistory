, 'mu_eps_star_GED_beta'
, 'M21_M22_level_mu_delta'
, 'M21_M22_level_sd_delta'
, 'mu_omega_star'
, 'vol_shock_sd'
, 'M21_M22_vol_mu_delta'
, 'M21_M22_vol_sd_delta'
, 'normchoice'
)
fitting_output_subset <- as.data.frame(t(unlist(fitting_output[,-c(1,6)])))
#Now we combine the output
all_output_combined <- cbind(parameters_to_output, fitting_output_subset)
return(all_output_combined)
}
simulate_and_analyze(plot_fit = TRUE)
# David Lundquist
# Wrapper for Simulations for Synthetic Prediction GARCH
#We will need the two functions here.
source('~/Desktop/synthetic_vol_forecasting/synthVolForecast.R',
echo = FALSE,
verbose = FALSE)
simulate_and_analyze <- function(n = 12,
p = 9,
model = NULL,
arch_param = c(.26),
garch_param = c(.4),
asymmetry_param = c(),
level_model = c('M1','M21','M22','none')[4],
vol_model = c('M1','M21','M22','none')[2],
sigma_GARCH_innov = 1, # the sd that goes into rnorm
sigma_x = 1, # the sd that goes into the covariates
min_shock_time = 0,
shock_time_vec = NULL,
level_shock_length = 1,
vol_shock_length = 2,
extra_measurement_days = 2,
a = 3*252,
b = 10*252,
mu_eps_star = -4.25,
mu_eps_star_GED_alpha = sqrt(2), # note: beta = 2, alpha = sqrt(2) is N(0,1)
mu_eps_star_GED_beta = 2, # note: beta = 2, alpha = sqrt(2) is N(0,1))
M21_M22_level_mu_delta = .3,
M21_M22_level_sd_delta = .05,
mu_omega_star = .005,
vol_shock_sd = .0001,
M21_M22_vol_mu_delta = .05,
M21_M22_vol_sd_delta = .002,
plot_sim = FALSE,
plot_fit = FALSE,
# And now the only inputs for the fitting function
evaluated_vol_shock_length = rep(2, n+1),
normchoice = 'l2'
)
{
## Doc String
# simulate_and_analyze: function wraps two functions:
# (1) synth_vol_sim
# (2) synth_vol_fit
# --Input:
#   --n - number of donors (scalar)
#   --model - model order for a parameters to be simulated (optional).
#     If specified, then arch, garch parameter values overridden.
#   --p - number of covariates (scalar)
#   --arch parameters (vector of length 0 or more)
#   --garch parameters (vector of length 0 or more)
#   --asymmetry_param (vector of length 0 or more)
#   --level_model - model for level of the shock (string)
#   --vol_model - model for volatility of the shock (string)
#   --sigma_GARCH_innov (scalar)
#   --sigma_x - sigma of innovations in covariates (scalar)
#   --min_shock_time - the minimum number of points after the min series length 'a' that the shock can occur at
#   --shock_time_vec - optional input to force shock times (vector of integers)
#   --level_shock_length (scalar)
#   --vol_shock_length (scalar)
#   --a - minumum series length (scalar)
#   --b - maximum series length (scalar)
#   --mu_eps_star - intercept for each of the level shock models
#   --M21_M22_mu_delta - mean of delta for M21, M22 level models
#   --M21_M22_level_sd_delta - sd of the vector delta in M21 and M22 level models
#   --mu_omega_star - intercept of vol shock for M1 model
#   --M21_M22_mu_omega_star - mean of delta for M21, M22 vol models
#   --vol_shock_sd - variance of the error in all volatility models
#   --M21_M22_vol_sd_delta - sd of the vector delta in M21 and M22 vol models
#   --mu_eps_star_GED_alpha - alpha parameter for level shock stochastic term
#   --mu_eps_star_GED_beta - beta parameter for level shock stochastic term
#   --evaluated_vol_shock_length - vector of length n+1 referring to the shocks lengths to be used in the estimation process
sim_output <- synth_vol_sim(n = n,
p = p,
#model = c(1,1,1),
arch_param = arch_param,
garch_param = garch_param,
#asymmetry_param = c(.15),
level_model = level_model,
vol_model = vol_model,
sigma_GARCH_innov = sigma_GARCH_innov, # the sd that goes into rnorm
sigma_x = sigma_x, # the sd that goes into the covariates
min_shock_time = min_shock_time,
shock_time_vec = shock_time_vec,
level_shock_length = level_shock_length,
vol_shock_length = vol_shock_length,
a = a,
b = b,
mu_eps_star = mu_eps_star,
mu_eps_star_GED_alpha = mu_eps_star_GED_alpha, # note: beta = 2, alpha = sqrt(2) is N(0,1)
mu_eps_star_GED_beta = mu_eps_star_GED_beta, # note: beta = 2, alpha = sqrt(2) is N(0,1)
M21_M22_level_mu_delta = M21_M22_level_mu_delta,
M21_M22_level_sd_delta = M21_M22_level_sd_delta,
mu_omega_star = mu_omega_star,
vol_shock_sd = vol_shock_sd,
M21_M22_vol_mu_delta = M21_M22_vol_mu_delta,
M21_M22_vol_sd_delta = M21_M22_vol_sd_delta,
plot = plot_sim)
# Let's now use the fitting function
X_demo <- sim_output[[1]]
Y_demo <- sim_output[[2]]
T_star_demo <- sim_output[[4]]
shock_effect_vec_demo <- sim_output[[5]][,1]
garch_order_of_simulation <- sapply(sim_output[[6]], length)
fitting_output <- synth_vol_fit(X = X_demo,
Y = Y_demo,
T_star = T_star_demo,
shock_est_vec = shock_effect_vec_demo,
shock_lengths = evaluated_vol_shock_length,
garch_order_of_simulation[1],
garch_order_of_simulation[2],
garch_order_of_simulation[3],
normchoice = normchoice,
plots = plot_fit
)
# Here we collect all the items we want to output
parameters_to_output <- as.data.frame(matrix(
c(n
, p
, arch_param
, garch_param
, level_model
, vol_model
, sigma_GARCH_innov
, sigma_x
, min_shock_time
#, shock_time_vec
, level_shock_length
, vol_shock_length
#, evaluated_vol_shock_length
, extra_measurement_days
, a
, b
, mu_eps_star
, mu_eps_star_GED_alpha
, mu_eps_star_GED_beta
, M21_M22_level_mu_delta
, M21_M22_level_sd_delta
, mu_omega_star
, vol_shock_sd
, M21_M22_vol_mu_delta
, M21_M22_vol_sd_delta
, normchoice
)
, nrow = 1))
names(parameters_to_output) <- c('n'
, 'p'
, 'arch_param'
, 'garch_param'
, 'level_model'
, 'vol_model'
, 'sigma_GARCH_innov'
, 'sigma_x'
, 'min_shock_time'
#, 'shock_time_vec'
, 'level_shock_length'
, 'vol_shock_length'
#, 'evaluated_vol_shock_length'
, 'extra_measurement_days'
, 'a'
, 'b'
, 'mu_eps_star'
, 'mu_eps_star_GED_alpha'
, 'mu_eps_star_GED_beta'
, 'M21_M22_level_mu_delta'
, 'M21_M22_level_sd_delta'
, 'mu_omega_star'
, 'vol_shock_sd'
, 'M21_M22_vol_mu_delta'
, 'M21_M22_vol_sd_delta'
, 'normchoice'
)
fitting_output_subset <- as.data.frame(t(unlist(fitting_output[,-c(1,6)])))
#Now we combine the output
all_output_combined <- cbind(parameters_to_output, fitting_output_subset)
return(all_output_combined)
}
simulate_and_analyze(plot_fit = TRUE)
# David Lundquist
# Wrapper for Simulations for Synthetic Prediction GARCH
#We will need the two functions here.
source('~/Desktop/synthetic_vol_forecasting/synthVolForecast.R',
echo = FALSE,
verbose = FALSE)
simulate_and_analyze <- function(n = 12,
p = 9,
model = NULL,
arch_param = c(.26),
garch_param = c(.4),
asymmetry_param = c(),
level_model = c('M1','M21','M22','none')[4],
vol_model = c('M1','M21','M22','none')[2],
sigma_GARCH_innov = 1, # the sd that goes into rnorm
sigma_x = 1, # the sd that goes into the covariates
min_shock_time = 0,
shock_time_vec = NULL,
level_shock_length = 1,
vol_shock_length = 2,
extra_measurement_days = 2,
a = 3*252,
b = 10*252,
mu_eps_star = -4.25,
mu_eps_star_GED_alpha = sqrt(2), # note: beta = 2, alpha = sqrt(2) is N(0,1)
mu_eps_star_GED_beta = 2, # note: beta = 2, alpha = sqrt(2) is N(0,1))
M21_M22_level_mu_delta = .3,
M21_M22_level_sd_delta = .05,
mu_omega_star = .005,
vol_shock_sd = .0001,
M21_M22_vol_mu_delta = .05,
M21_M22_vol_sd_delta = .002,
plot_sim = FALSE,
plot_fit = FALSE,
# And now the only inputs for the fitting function
evaluated_vol_shock_length = rep(2, n+1),
normchoice = 'l2'
)
{
## Doc String
# simulate_and_analyze: function wraps two functions:
# (1) synth_vol_sim
# (2) synth_vol_fit
# --Input:
#   --n - number of donors (scalar)
#   --model - model order for a parameters to be simulated (optional).
#     If specified, then arch, garch parameter values overridden.
#   --p - number of covariates (scalar)
#   --arch parameters (vector of length 0 or more)
#   --garch parameters (vector of length 0 or more)
#   --asymmetry_param (vector of length 0 or more)
#   --level_model - model for level of the shock (string)
#   --vol_model - model for volatility of the shock (string)
#   --sigma_GARCH_innov (scalar)
#   --sigma_x - sigma of innovations in covariates (scalar)
#   --min_shock_time - the minimum number of points after the min series length 'a' that the shock can occur at
#   --shock_time_vec - optional input to force shock times (vector of integers)
#   --level_shock_length (scalar)
#   --vol_shock_length (scalar)
#   --a - minumum series length (scalar)
#   --b - maximum series length (scalar)
#   --mu_eps_star - intercept for each of the level shock models
#   --M21_M22_mu_delta - mean of delta for M21, M22 level models
#   --M21_M22_level_sd_delta - sd of the vector delta in M21 and M22 level models
#   --mu_omega_star - intercept of vol shock for M1 model
#   --M21_M22_mu_omega_star - mean of delta for M21, M22 vol models
#   --vol_shock_sd - variance of the error in all volatility models
#   --M21_M22_vol_sd_delta - sd of the vector delta in M21 and M22 vol models
#   --mu_eps_star_GED_alpha - alpha parameter for level shock stochastic term
#   --mu_eps_star_GED_beta - beta parameter for level shock stochastic term
#   --evaluated_vol_shock_length - vector of length n+1 referring to the shocks lengths to be used in the estimation process
sim_output <- synth_vol_sim(n = n,
p = p,
#model = c(1,1,1),
arch_param = arch_param,
garch_param = garch_param,
#asymmetry_param = c(.15),
level_model = level_model,
vol_model = vol_model,
sigma_GARCH_innov = sigma_GARCH_innov, # the sd that goes into rnorm
sigma_x = sigma_x, # the sd that goes into the covariates
min_shock_time = min_shock_time,
shock_time_vec = shock_time_vec,
level_shock_length = level_shock_length,
vol_shock_length = vol_shock_length,
a = a,
b = b,
mu_eps_star = mu_eps_star,
mu_eps_star_GED_alpha = mu_eps_star_GED_alpha, # note: beta = 2, alpha = sqrt(2) is N(0,1)
mu_eps_star_GED_beta = mu_eps_star_GED_beta, # note: beta = 2, alpha = sqrt(2) is N(0,1)
M21_M22_level_mu_delta = M21_M22_level_mu_delta,
M21_M22_level_sd_delta = M21_M22_level_sd_delta,
mu_omega_star = mu_omega_star,
vol_shock_sd = vol_shock_sd,
M21_M22_vol_mu_delta = M21_M22_vol_mu_delta,
M21_M22_vol_sd_delta = M21_M22_vol_sd_delta,
plot = plot_sim)
# Let's now use the fitting function
X_demo <- sim_output[[1]]
Y_demo <- sim_output[[2]]
T_star_demo <- sim_output[[4]]
shock_effect_vec_demo <- sim_output[[5]][,1]
garch_order_of_simulation <- sapply(sim_output[[6]], length)
fitting_output <- synth_vol_fit(X = X_demo,
Y = Y_demo,
T_star = T_star_demo,
shock_est_vec = shock_effect_vec_demo,
shock_lengths = evaluated_vol_shock_length,
garch_order_of_simulation[1],
garch_order_of_simulation[2],
garch_order_of_simulation[3],
normchoice = normchoice,
plots = plot_fit
)
# Here we collect all the items we want to output
parameters_to_output <- as.data.frame(matrix(
c(n
, p
, arch_param
, garch_param
, level_model
, vol_model
, sigma_GARCH_innov
, sigma_x
, min_shock_time
#, shock_time_vec
, level_shock_length
, vol_shock_length
#, evaluated_vol_shock_length
, extra_measurement_days
, a
, b
, mu_eps_star
, mu_eps_star_GED_alpha
, mu_eps_star_GED_beta
, M21_M22_level_mu_delta
, M21_M22_level_sd_delta
, mu_omega_star
, vol_shock_sd
, M21_M22_vol_mu_delta
, M21_M22_vol_sd_delta
, normchoice
)
, nrow = 1))
names(parameters_to_output) <- c('n'
, 'p'
, 'arch_param'
, 'garch_param'
, 'level_model'
, 'vol_model'
, 'sigma_GARCH_innov'
, 'sigma_x'
, 'min_shock_time'
#, 'shock_time_vec'
, 'level_shock_length'
, 'vol_shock_length'
#, 'evaluated_vol_shock_length'
, 'extra_measurement_days'
, 'a'
, 'b'
, 'mu_eps_star'
, 'mu_eps_star_GED_alpha'
, 'mu_eps_star_GED_beta'
, 'M21_M22_level_mu_delta'
, 'M21_M22_level_sd_delta'
, 'mu_omega_star'
, 'vol_shock_sd'
, 'M21_M22_vol_mu_delta'
, 'M21_M22_vol_sd_delta'
, 'normchoice'
)
fitting_output_subset <- as.data.frame(t(unlist(fitting_output[,-c(1,6)])))
#Now we combine the output
all_output_combined <- cbind(parameters_to_output, fitting_output_subset)
return(all_output_combined)
}
simulate_and_analyze(plot_fit = TRUE)
?norm
rm(list = ls())
options(digits = 6)
load("/home/david/Desktop/simcount_2_savetime_SunMar0519:17:582023_runtime_-3.11301105876764_grid_size5184_recovery_0.803144290123457_permute_0.Rdata")
load("/home/david/Desktop/synthetic_vol_forecasting/simulation_results/simcount_2_savetime_SunMar0519:17:582023_runtime_-3.11301105876764_grid_size5184_recovery_0.803144290123457_permute_0.Rdata")
library(lmboot)
length_unique <- function(x) {return(length(unique(x)))}
#Check that things vary correctly cross vol models
check <- output %>% group_by(vol_model) %>%
summarise(across(everything(), length_unique),
.groups = 'drop')  %>%
as.data.frame()
check
# We look for the columns that have no variation, i.e. those with only 1 value.
unique_count_df <- apply(output, 2, function(x) length(unique(x)))
# We look for the columns that have no variation, i.e. those with only 1 value.
unique_count_df <- apply(output, 2, function(x) length(unique(x)))
# We drop these columns.
columns_we_want <- names(unique_count_df)[unique_count_df != 1]
reduced_df <- output[names(output) %in% columns_we_want]
#First specify which vol model one want to focus on
vol_model_chosen <- reduced_df[reduced_df$vol_model == 2,]
#Look for missing values
library(Amelia)
missmap(reduced_df, main = "Missing values vs observed")
# Make the dataframe numeric
vol_model_chosen <- as.data.frame(lapply(vol_model_chosen, as.numeric))
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:10)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
non_NA <- df_only_one_outcome[complete.cases(df_only_one_outcome),]
non_NA
names(non_NA)
means <- non_NA %>% group_by(vol_model) %>% summarise(across(everything(), list(means)))
means <- as.data.frame(means)
means
load("/home/david/Desktop/synthetic_vol_forecasting/simulation_results/simcount_2_savetime_SunMar0519:17:582023_runtime_-3.11301105876764_grid_size5184_recovery_0.803144290123457_permute_0.Rdata")
names(output)
library(lmboot)
length_unique <- function(x) {return(length(unique(x)))}
#Check that things vary correctly cross vol models
check <- output %>% group_by(vol_model) %>%
summarise(across(everything(), length_unique),
.groups = 'drop')  %>%
as.data.frame()
library(dplyr)
options(digits = 6)
load("/home/david/Desktop/synthetic_vol_forecasting/simulation_results/simcount_2_savetime_SunMar0519:17:582023_runtime_-3.11301105876764_grid_size5184_recovery_0.803144290123457_permute_0.Rdata")
library(lmboot)
length_unique <- function(x) {return(length(unique(x)))}
#Check that things vary correctly cross vol models
check <- output %>% group_by(vol_model) %>%
summarise(across(everything(), length_unique),
.groups = 'drop')  %>%
as.data.frame()
check
# We look for the columns that have no variation, i.e. those with only 1 value.
unique_count_df <- apply(output, 2, function(x) length(unique(x)))
# We drop these columns.
columns_we_want <- names(unique_count_df)[unique_count_df != 1]
reduced_df <- output[names(output) %in% columns_we_want]
#First specify which vol model one want to focus on
vol_model_chosen <- reduced_df[reduced_df$vol_model == 2,]
#Look for missing values
library(Amelia)
# Make the dataframe numeric
vol_model_chosen <- as.data.frame(lapply(vol_model_chosen, as.numeric))
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:10)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
names(vol_model_chosen)
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:11)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
non_NA <- df_only_one_outcome[complete.cases(df_only_one_outcome),]
#Let's do an analysis by volatility model
library(dplyr)
means <- non_NA %>% group_by(vol_model) %>% summarise(across(everything(), list(means)))
means <- as.data.frame(means)
means
names(non_NA)
model <- glm(non_NA[,12] ~. , family=binomial(link='logit'),data=non_NA[,c(1:6,11)])
non_NA
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:11)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
non_NA <- df_only_one_outcome[complete.cases(df_only_one_outcome),]
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:11)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
#First specify which vol model one want to focus on
vol_model_chosen <- reduced_df[reduced_df$vol_model == 2,]
#First specify which vol model one want to focus on
vol_model_chosen <- reduced_df[reduced_df$vol_model == 1,]
# Make the dataframe numeric
vol_model_chosen <- as.data.frame(lapply(vol_model_chosen, as.numeric))
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:11)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
non_NA <- df_only_one_outcome[complete.cases(df_only_one_outcome),]
model <- glm(non_NA[,12] ~. , family=binomial(link='logit'),data=non_NA[,c(1:6,11)])
names(reduced_df)
reduced_df <- output[names(output) %in% columns_we_want]
# Make the dataframe numeric
vol_model_chosen <- as.data.frame(lapply(vol_model_chosen, as.numeric))
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:11)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
non_NA <- df_only_one_outcome[complete.cases(df_only_one_outcome),]
model <- glm(non_NA[,12] ~. , family=binomial(link='logit'),data=non_NA[,c(1:6,11)])
summary(model)
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:11)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
#First specify which vol model one want to focus on
#vol_model_chosen <- reduced_df[reduced_df$vol_model == 1,]
vol_model_chosen <- reduced_df
# Make the dataframe numeric
vol_model_chosen <- as.data.frame(lapply(vol_model_chosen, as.numeric))
df_only_one_outcome <- cbind(vol_model_chosen[,c(1:11)], as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14))
non_NA <- df_only_one_outcome[complete.cases(df_only_one_outcome),]
model <- glm(non_NA[,12] ~. , family=binomial(link='logit'),data=non_NA[,c(1:6,11)])
summary(model)
names(non_NA)
summary(model)
hist(non_NA$vol_sig_noise_ratio)
plot(density(non_NA$vol_sig_noise_ratio))
model <- glm(non_NA[,12] ~.^2 , family=binomial(link='logit'),data=non_NA[,c(1:6,11)])
summary(model)
c2 <- non_NA$p > 5
names(non_NA)
dom_subset <- non_NA[c1 & c2 & c3 & c4 & c5 & c6,]
## Hyperplanes
c1 <- non_NA$n > 5
c2 <- non_NA$p > 5
c3 <- non_NA$arch_param < .2
c4 <- non_NA$garch_param < .2
c5 <- non_NA$vol_shock_length > 1
c6 <- non_NA$vol_sig_noise_ratio > 1.2
dom_subset <- non_NA[c1 & c2 & c3 & c4 & c5 & c6,]
nrow(dom_subset)
mean(dom_subset$`as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14)`)
c6 <- non_NA$vol_sig_noise_ratio > 1.9
dom_subset <- non_NA[c1 & c2 & c3 & c4 & c5 & c6,]
nrow(dom_subset)
mean(dom_subset$`as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14)`)
c6 <- non_NA$vol_sig_noise_ratio > 2.9
dom_subset <- non_NA[c1 & c2 & c3 & c4 & c5 & c6,]
nrow(dom_subset)
mean(dom_subset$`as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14)`)
means <- non_NA %>% group_by(vol_model) %>% summarise(across(everything(), list(means)))
c6 <- non_NA$vol_sig_noise_ratio > 3.9
dom_subset <- non_NA[c1 & c2 & c3 & c4 & c5 & c6,]
nrow(dom_subset)
mean(dom_subset$`as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14)`)
c6 <- non_NA$vol_sig_noise_ratio > 5.9
dom_subset <- non_NA[c1 & c2 & c3 & c4 & c5 & c6,]
nrow(dom_subset)
mean(dom_subset$`as.integer(vol_model_chosen$QL_adj1 <= vol_model_chosen$QL_adj14)`)
